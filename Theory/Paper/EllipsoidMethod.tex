\section{Метод эллипсоидов}

Рассмотрим алгоритм решения задачи выпуклого программирования, гарантирующий уменьшение объема области, в которой локализуется оптимум, со скоростью геометрической прогрессии, причем знаменатель этой прогрессии зависит только от размерности задачи~\cite{Stecuk2014}.

Пусть имеется задача выпуклого программирования:
\begin{equation}
\min f_0(x)
\end{equation}
при ограничениях
\begin{equation}
\label{eqLimits}
f_i(x)\le 0,\mbox{ }i=1,\ldots,m,\mbox{ }x\in E_n.
\end{equation}
$f_\nu(x)$ -- выпуклые функции, определенные на $E_n$; $g_\nu(x)$ -- соответствующие субградиенты, причем имеется априорная информация, что оптимальная точка $x^*$ существует (она не обязательно единственная) и находится в шаре радиуса $R$ с центром в точке $x_0$ (формально к системе ограничений~\ref{eqLimits} можно добавить ограничение $||x-x_0||\le R$).

Рассмотрим следующий итеративный алгоритм (при $n>1$).

Перед первым шагом имеем $x_0\in E_n$, $B_0=I$ -- единичная матрица, $h_0=\frac{R}{n+1}$. Пусть проделано $k$ шагов и получены $x_k\in E_n$; $B_k$ -- матрица $n\times n$, $h_k>0$.

$(k+1)$-й шаг. Вычисляем:
\begin{flalign}
&\mbox{1) }g(x_k)=
\left\{
\begin{tabular}{ll}
$g_0(x_k)$, & если $\displaystyle\max_{1\le i\le m}f_i(x_k)\le 0$, \\
$g_{i^*}(x_k)$, & если $\displaystyle\max_{1\le i\le m}f_i(x_k)=f_{i^*}(x_k)>0$. \\
\end{tabular}
\right.
&\\
&\mbox{Если $g(x_k)=0$, то $x_k$ -- оптимальная точка; важно заметить, что}\nonumber
&\\
&\mbox{$\left(g(x_k),x_k-x^*\right)\ge 0$;}\nonumber
&\\
&\mbox{2) }\xi=\frac{B_k^*g(x_k)}{||B_k^*g(x_k)||};
&\\
&\mbox{3) }x_{k+1}=x_k-h_k\cdot B_k\cdot\xi_k;
&\\
&\mbox{4) }B_{k+1}=B_k\cdot R_\beta(\xi_k),\mbox{ }\beta=\sqrt{\frac{n-1}{n+1}};
&\\
&\mbox{$R_\beta(\xi_k)$ -- оператор растяжения пространства в направлении $\xi_k$ с}\nonumber
&\\
&\mbox{коэффициентом $\beta$;}\nonumber
&\\
&\mbox{5) }h_{k+1}=h_k\cdot r,\mbox{ }r=\frac{n}{\sqrt{n^2-1}}.&
\end{flalign}
