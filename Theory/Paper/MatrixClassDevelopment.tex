\subsection{Распараллеливание матричных операций}

В первой главе показано, что метод эллипсоидов активно использует матричные операции. Вычислительная сложность матричных операций варьируется от $O(n^2)$ (сложение, вычитание, транспонирование) до $O(n^3)$ (умножение). Ускорив выполнение этих операций, можно добиться ускорения выполнение всего метода.

Стандартная библиотека C++ не предоставляет класса для представления матриц в программе. Для языка существуют различные реализации класса матриц, работающие без использования многопоточности~\cite{Boost, Armadillo, ItPlusPlus}. Для ускорения работы метода эллипсоидов требуется разработать класс матриц, поддерживающий распараллеливание матричных операций.

Полный исходный код класса приведен в приложении~\ref{app:matrixSource}. Здесь рассматриваются основные идеи, лежащие в данной реализации.

Класс \texttt{Matrix} -- шаблонный класс, параметризованный типом \texttt{T} элементов матрицы.

\lstset{
caption=,
numbers=none,
frame=none
}

\lstinputlisting[firstline=11,lastline=12,firstnumber=11]{../../Practice/Matrix.h}

В классе используется следующие обозначения типов.

\lstinputlisting[firstline=16,lastline=18,firstnumber=16]{../../Practice/Matrix.h}

Класс предоставляет три конструктора. Первый создает матрицу указанной размерности, все элементы которой заполнены начальным значением.

\lstinputlisting[firstline=25,lastline=25,firstnumber=25]{../../Practice/Matrix.h}

Второй -- конструктор копирования -- создает матрицу, все элементы которой равны элементам указанной матрицы.

\lstinputlisting[firstline=38,lastline=38,firstnumber=38]{../../Practice/Matrix.h}

Третий -- конструктор перемещения -- берет во владение ресурсы временно созданной матрицы.

\lstinputlisting[firstline=50,lastline=50,firstnumber=50]{../../Practice/Matrix.h}

Для индексного доступа к элементам применяются две версии оператора вызова функции (для константных и неконстантных объектов).

\lstinputlisting[firstline=62,lastline=62,firstnumber=62]{../../Practice/Matrix.h}

\lstinputlisting[firstline=73,lastline=73,firstnumber=73]{../../Practice/Matrix.h}

Имеются две версии оператора присваивания (по копии и по временному объекту).

\lstinputlisting[firstline=84,lastline=84,firstnumber=84]{../../Practice/Matrix.h}

\lstinputlisting[firstline=101,lastline=101,firstnumber=101]{../../Practice/Matrix.h}

Для класса перегружены основные бинарные операторы.

\lstinputlisting[firstline=119,lastline=119,firstnumber=119]{../../Practice/Matrix.h}

\lstinputlisting[firstline=149,lastline=149,firstnumber=149]{../../Practice/Matrix.h}

\lstinputlisting[firstline=179,lastline=179,firstnumber=179]{../../Practice/Matrix.h}

Операторы сравнения выполняют проверку на равенство элементов двух матриц.

\lstinputlisting[firstline=210,lastline=210,firstnumber=210]{../../Practice/Matrix.h}

\lstinputlisting[firstline=232,lastline=232,firstnumber=232]{../../Practice/Matrix.h}

Для операции транспонирования класс предоставляет функцию.

\lstinputlisting[firstline=240,lastline=240,firstnumber=240]{../../Practice/Matrix.h}

Две функции для получения информации о размерности матрицы.

\lstinputlisting[firstline=250,lastline=250,firstnumber=250]{../../Practice/Matrix.h}

\lstinputlisting[firstline=258,lastline=258,firstnumber=258]{../../Practice/Matrix.h}

Это открытый интерфейс класса \texttt{Matrix}, доступный пользователю. Помимо перечисленного функционала, класс содержит статическую функцию для доступа к объекту, управляющему механизмом параллельного выполнения операций.

\lstinputlisting[firstline=266,lastline=266,firstnumber=266]{../../Practice/Matrix.h}

Для многих методов матричных вычислений характерным является повторение одних и тех же вычислительных действий для разных элементов матриц. Данный момент свидетельствует о наличии \emph{параллелизма по данным} при выполнении матричных расчетов и, как результат, распараллеливание матричных операций сводится в большинстве случаев к разделению обрабатываемых матриц между потоками. Выбор способа разделения матриц приводит к определению конкретного метода параллельных вычислений; существование разных схем распределения данных порождает целый ряд \emph{параллельных алгоритмов матричных вычислений}.

Наиболее общие и широко используемые способы разделения матриц состоят в разбиении данных на \emph{полосы} (по вертикали или горизонтали) или на прямоугольные фрагменты (\emph{блоки})~\cite{Dongarra1999}.

При \emph{ленточном} (block--striped) разбиении каждому потоку выделяется то или иное подмножество строк (\emph{rowwise} или \emph{горизонтальное разбиение}) или столбцов (\emph{columnwise} или \emph{вертикальное разбиение}) матрицы (графическая иллюстрация перечисленных подходов представлена на рисунке~\ref{fig:MatrixBlocks}~\cite{Intuit}). Разделение строк и столбцов на полосы в большинстве случаев происходит на \emph{непрерывной} (\emph{последовательной}) основе. При таком подходе для горизонтального разбиения по строкам, матрица $A$ представляется в виде $$A=(A_0,A_1,\ldots,A_{p-1})^T,A_i=(a_{i_0},a_{i_1},\ldots,a_{i_{k-1}}),i_j=ik+j,0\le j<k,k=m/p,$$ где $a_i=(a_{i1},a_{i2},\ldots,a_{in}),\quad 0\le i<m$, есть $i$-я строка матрицы $A$ (предполагается, что количество строк $m$ кратно числу вычислительных элементов (процессоров и/или ядер) $p$, т.е. $m=k\cdot p$). Существуют и другие способы разбиения, например, блочный.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{Figures/MatrixBlocks}
\caption{\label{fig:MatrixBlocks} Способы разбиения элементов матрицы (слева направо): горизонтальный, вертикальный и блочный}
\end{figure}

\texttt{ParallelHandler} инкапсулирует параллельное выполнение матричных операций, применяя ленточное разбиение данных на непрерывной основе. Для этого класс предоставляет шаблонную функцию, параметризованную типом итератора и функции.

\lstinputlisting[firstline=27,lastline=30,firstnumber=27]{../../Practice/ParallelHandler.h}

Функция создает и управляет потоками, количество которых зависит от текущих настроек. Класс оперирует понятием \emph{политики распараллеливания}, которое может обозначать один из двух типов: \emph{автоматически} и \emph{вручную}.

\lstinputlisting[firstline=15,lastline=19,firstnumber=15]{../../Practice/ParallelHandler.h}

Для установки этих и других значений применяется следующий набор функций.

\lstinputlisting[firstline=61,lastline=64,firstnumber=61]{../../Practice/ParallelHandler.h}

Функции имеют следующие значения (в порядке объявления): использовать автоматический расчет количества потоков, задать количество потоков вручную, задать минимальную ширину ленты при разбиении данных, установить нижнюю границу для числа используемых потоков.

Для разработанного класса необходимо провести анализ эффективности, доказывающий его преимущество перед последовательным выполнением.

Алгоритмы параллельных матричных операций, основанные на ленточном горизонтальном разбиении матрицы, обладают хорошей <<локализацией вычислений>>, т.е. каждый поток параллельной программы использует только <<свои>> данные, и ему не требуются данные, которые в данный момент обрабатывает другой поток, нет обмена данными между потоками, не возникает необходимости синхронизации. Это означает, что практически не существуют накладные расходы на организацию параллелизма (за исключением расходов на создание/завершение потоков), и можно ожидать линейного ускорения.

Однако, как видно из представленных результатов, ускорение, которое демонстрируют параллельные матричные операции, далеко от линейного.

Задача умножения матриц обладает сравнительно невысокой вычислительной сложностью -- трудоемкость алгоритма имеет порядок $O(n^2)$. Такой же порядок -- $O(n^2)$ -- имеет и объем данных, обрабатываемый алгоритмом умножения. Время решения задачи одним потоком складывается из времени, когда процессор непосредственно выполняет вычисления, и времени, которое тратится на чтение необходимых для вычислений данных из оперативной памяти в кэш память. При этом время, необходимое для чтения данных, может быть сопоставимо или даже превосходить время счета.

Проведем вычислительный эксперимент: измерим время выполнения последовательного и параллельного алгоритма суммирования и умножения матриц.

При суммировании элементов матрицы на каждой итерации цикла выполняется простая операция сложения двух чисел. При умножении матриц на каждой итерации цикла выполняются две операции: более сложная операция умножения и операция сложения. Но, несмотря на большую вычислительную сложность, время работы алгоритма умножения матриц превосходит время выполнения сложения всего на [TODO: X\%]. Этот эксперимент можно рассматривать, как подтверждение предположения о том, что значительная часть времени тратится на выборку необходимых данных из оперативной памяти в кэш процессора.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/MultiplicationAcceleration}
\caption{\label{fig:MultiplicationAcceleration} MultiplicationAcceleration}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/MultiplicationTime}
\caption{\label{fig:MultiplicationTime} MultiplicationTime}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/SummarizingAcceleration}
\caption{\label{fig:SummarizingAcceleration} SummarizingAcceleration}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/SummarizingTime}
\caption{\label{fig:SummarizingTime} SummarizingTime}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/ThreadsNumberTime}
\caption{\label{fig:ThreadsNumberTime} ThreadsNumberTime}
\end{figure}