\subsection{Распараллеливание матричных операций}

В первой главе показано, что метод эллипсоидов активно использует матричные операции. Вычислительная сложность матричных операций варьируется от $O(n^2)$ (сложение, вычитание, транспонирование) до $O(n^3)$ (умножение). Ускорив выполнение этих операций, можно добиться ускорения выполнение всего метода.

Стандартная библиотека C++ не предоставляет класса для представления матриц в программе. Для языка существуют различные реализации класса матриц, работающие без использования многопоточности~\cite{Boost, Armadillo, ItPlusPlus}. Для ускорения работы метода эллипсоидов требуется разработать класс матриц, поддерживающий распараллеливание матричных операций.

Полный исходный код класса приведен в приложении~\ref{app:matrixSource}. Здесь рассматриваются основные идеи, лежащие в данной реализации.

Класс \texttt{Matrix} -- шаблонный класс, параметризованный типом \texttt{T} элементов матрицы.

\lstset{
caption=,
numbers=none,
frame=none
}

\lstinputlisting[firstline=11,lastline=12,firstnumber=11]{../../Practice/Matrix.h}

В классе используется следующие обозначения типов.

\lstinputlisting[firstline=16,lastline=18,firstnumber=16]{../../Practice/Matrix.h}

Класс предоставляет три конструктора. Первый создает матрицу указанной размерности, все элементы которой заполнены начальным значением.

\lstinputlisting[firstline=25,lastline=25,firstnumber=25]{../../Practice/Matrix.h}

Второй -- конструктор копирования -- создает матрицу, все элементы которой равны элементам указанной матрицы.

\lstinputlisting[firstline=38,lastline=38,firstnumber=38]{../../Practice/Matrix.h}

Третий -- конструктор перемещения -- берет во владение ресурсы временно созданной матрицы.

\lstinputlisting[firstline=50,lastline=50,firstnumber=50]{../../Practice/Matrix.h}

Для индексного доступа к элементам применяются две версии оператора вызова функции (для константных и неконстантных объектов).

\lstinputlisting[firstline=62,lastline=62,firstnumber=62]{../../Practice/Matrix.h}

\lstinputlisting[firstline=73,lastline=73,firstnumber=73]{../../Practice/Matrix.h}

Имеются две версии оператора присваивания (по копии и по временному объекту).

\lstinputlisting[firstline=84,lastline=84,firstnumber=84]{../../Practice/Matrix.h}

\lstinputlisting[firstline=101,lastline=101,firstnumber=101]{../../Practice/Matrix.h}

Для класса перегружены основные бинарные операторы.

\lstinputlisting[firstline=119,lastline=119,firstnumber=119]{../../Practice/Matrix.h}

\lstinputlisting[firstline=149,lastline=149,firstnumber=149]{../../Practice/Matrix.h}

\lstinputlisting[firstline=179,lastline=179,firstnumber=179]{../../Practice/Matrix.h}

Операторы сравнения выполняют проверку на равенство элементов двух матриц.

\lstinputlisting[firstline=234,lastline=234,firstnumber=234]{../../Practice/Matrix.h}

\lstinputlisting[firstline=256,lastline=256,firstnumber=256]{../../Practice/Matrix.h}

Для операции транспонирования класс предоставляет функцию.

\lstinputlisting[firstline=264,lastline=264,firstnumber=264]{../../Practice/Matrix.h}

Две функции для получения информации о размерности матрицы.

\lstinputlisting[firstline=274,lastline=274,firstnumber=274]{../../Practice/Matrix.h}

\lstinputlisting[firstline=282,lastline=282,firstnumber=282]{../../Practice/Matrix.h}

Это открытый интерфейс класса \texttt{Matrix}, доступный пользователю. Помимо перечисленного функционала, класс содержит статическую функцию для доступа к объекту, управляющему механизмом параллельного выполнения операций.

\lstinputlisting[firstline=290,lastline=290,firstnumber=290]{../../Practice/Matrix.h}

Для многих методов матричных вычислений характерным является повторение одних и тех же вычислительных действий для разных элементов матриц. Данный момент свидетельствует о наличии \emph{параллелизма по данным} при выполнении матричных расчетов и, как результат, распараллеливание матричных операций сводится в большинстве случаев к разделению обрабатываемых матриц между потоками. Выбор способа разделения матриц приводит к определению конкретного метода параллельных вычислений; существование разных схем распределения данных порождает целый ряд \emph{параллельных алгоритмов матричных вычислений}.

Наиболее общие и широко используемые способы разделения матриц состоят в разбиении данных на \emph{полосы} (по вертикали или горизонтали) или на прямоугольные фрагменты (\emph{блоки})~\cite{Dongarra1999}.

При \emph{ленточном} (block--striped) разбиении каждому потоку выделяется то или иное подмножество строк (\emph{rowwise} или \emph{горизонтальное разбиение}) или столбцов (\emph{columnwise} или \emph{вертикальное разбиение}) матрицы (графическая иллюстрация перечисленных подходов представлена на рисунке~\ref{fig:MatrixBlocks}~\cite{Intuit}). Разделение строк и столбцов на полосы в большинстве случаев происходит на \emph{непрерывной} (\emph{последовательной}) основе. При таком подходе для горизонтального разбиения по строкам, матрица $A$ представляется в виде $$A=(A_0,A_1,\ldots,A_{p-1})^T,A_i=(a_{i_0},a_{i_1},\ldots,a_{i_{k-1}}),i_j=ik+j,0\le j<k,k=m/p,$$ где $a_i=(a_{i1},a_{i2},\ldots,a_{in}),\quad 0\le i<m$, есть $i$-я строка матрицы $A$ (предполагается, что количество строк $m$ кратно числу вычислительных элементов (процессоров и/или ядер) $p$, т.е. $m=k\cdot p$). Существуют и другие способы разбиения, например, блочный.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{Figures/MatrixBlocks}
\caption{\label{fig:MatrixBlocks} Способы разбиения элементов матрицы (слева направо): горизонтальный, вертикальный и блочный}
\end{figure}

\texttt{ParallelHandler} инкапсулирует параллельное выполнение матричных операций, применяя ленточное разбиение данных на непрерывной основе. Для этого класс предоставляет шаблонную функцию, параметризованную типом итератора и функции.

\lstinputlisting[firstline=27,lastline=30,firstnumber=27]{../../Practice/ParallelHandler.h}

Функция создает и управляет потоками, количество которых зависит от текущих настроек. Класс оперирует понятием \emph{политики распараллеливания}, которое может обозначать один из двух типов: \emph{автоматически} и \emph{вручную}.

\lstinputlisting[firstline=15,lastline=19,firstnumber=15]{../../Practice/ParallelHandler.h}

Для установки этих и других значений применяется следующий набор функций.

\lstinputlisting[firstline=61,lastline=64,firstnumber=61]{../../Practice/ParallelHandler.h}

Функции имеют следующие значения (в порядке объявления): использовать автоматический расчет количества потоков, задать количество потоков вручную, задать минимальную ширину ленты при разбиении данных, установить нижнюю границу для числа используемых потоков.

Для разработанного класса необходимо провести анализ эффективности, доказывающий его преимущество перед последовательным выполнением.

Алгоритмы параллельных матричных операций, основанные на ленточном горизонтальном разбиении матрицы, обладают хорошей <<локализацией вычислений>>, т.е. каждый поток параллельной программы использует только <<свои>> данные, и ему не требуются данные, которые в данный момент обрабатывает другой поток, нет обмена данными между потоками, не возникает необходимости синхронизации. Это означает, что практически не существуют накладные расходы на организацию параллелизма (за исключением расходов на создание/завершение потоков), и можно ожидать линейного ускорения.

Однако, как видно из представленных ниже результатов, ускорение, которое демонстрируют параллельные матричные операции, далеко от линейного.

Задача умножения матриц обладает сравнительно невысокой вычислительной сложностью -- трудоемкость алгоритма имеет порядок $O(n^2)$. Такой же порядок -- $O(n^2)$ -- имеет и объем данных, обрабатываемый алгоритмом умножения. Время решения задачи одним потоком складывается из времени, когда процессор непосредственно выполняет вычисления, и времени, которое тратится на чтение необходимых для вычислений данных из оперативной памяти в кэш память. При этом время, необходимое для чтения данных, может быть сопоставимо или даже превосходить время счета.

Проведем вычислительный эксперимент: измерим время выполнения последовательного и параллельного алгоритма суммирования и умножения матриц. Столбиковые диаграммы замеров времени выполнения операций сложения и умножения матриц представлены на рисунках~\ref{fig:SummarizingTime} и~\ref{fig:MultiplicationTime} соответственно.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/SummarizingTime}
\caption{\label{fig:SummarizingTime} Время выполнения операции сложения матриц}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/MultiplicationTime}
\caption{\label{fig:MultiplicationTime} Время выполнения операции умножения матриц}
\end{figure}

При суммировании элементов матрицы на каждой итерации цикла выполняется простая операция сложения двух чисел. Здесь и далее под \emph{ускорением} выполнения операции будем понимать отношение времени выполнения операции в многопоточном режиме ко времени выполнения той же операции в однопоточном режиме. Достигнутое ускорение для операции сложения матриц различных размерностей представлено на рисунке~\ref{fig:SummarizingAcceleration}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/SummarizingAcceleration}
\caption{\label{fig:SummarizingAcceleration} Ускорение операции сложения матриц}
\end{figure}

Как видно из представленных рисунков, несмотря на меньшую вычислительную сложность, время работы параллельного алгоритма умножения матриц превосходит время выполнения однопоточной версии в среднем всего в $1.3$ раза. Этот эксперимент можно рассматривать, как подтверждение предположения о том, что значительная часть времени тратится на выборку необходимых данных из оперативной памяти в кэш процессора.

При умножении матриц на каждой итерации цикла выполняются две операции: более сложная операция умножения и операция сложения. Достигнутое ускорение для операции умножения матриц представлено на рисунке~\ref{fig:MultiplicationAcceleration}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/MultiplicationAcceleration}
\caption{\label{fig:MultiplicationAcceleration} Ускорение операции умножения матриц}
\end{figure}

Проведем другой эксперимент. Зафиксируем и положим равной $500\times 500$ размерность матриц--операндов. Будем выполнять операцию умножения матриц, применяя каждый раз различное количество потоков, чтобы определить поведение функции времени. Результаты эксперимента представлены на рисунке~\ref{fig:ThreadsNumberTime}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/ThreadsNumberTime}
\caption{\label{fig:ThreadsNumberTime} Зависимость времени выполения операции умножения матриц размерности $500\times 500$ от числа используемых потоков}
\end{figure}

Из рисунка~\ref{fig:ThreadsNumberTime} видно, что линейное увеличение количества используемых потоков приводит к нелинейному падению времени выполнения операции умножения. Из анализа результатов эксперимента также следует, что использование числа потоков большего, чем аппаратно поддерживается оборудованием, не приведет к дальнейшему падению функции времени. Такое замедление будет возникать из-за частых переключений планировщика потоков для симуляции параллелизма.

Таким образом, представленная реализация класса, представляющего матрицы в программе, действительно выполняется \emph{быстрее} и имеет \emph{ускорение, большее 1}, благодаря распараллеливанию вычислительно сложных матричных операций.